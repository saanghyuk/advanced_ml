{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(1,  32, 3, padding = 1) #input ch, output ch, kernel size, stride, padding\n",
    "conv2 = nn.Conv2d(32, 64, 3, 1, padding = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "print(conv1)\n",
    "print(conv2)\n",
    "\n",
    "# stride 에 아무런 값을 안주면 디폴트로 1이 들어감을 알 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ☆실제로 CNN 의 과정을 살펴보자☆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_data = torch.Tensor(1,1,28,28) # MNIST 의 실제 shape\n",
    "print(input_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$shape = \\displaystyle \\frac{(Input shape) - (kernel size)+ 2*(padding)}{stride} + 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input shape = (28,28) 이고 <br>\n",
    "첫번째 conv layer 를 통과하면 (28,28) - (3,3) + (2,2) + (1,1) = (28,28)<br>\n",
    "즉, channel 갯수만 늘고, shape 는 변하지 않음을 알 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(conv1(input_data).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.MaxPool2d(2) 의 경우 kernel size 가 2 라면 stride 도 2로 고정되어있다.<br>\n",
    "padding 은 물론 0<br><br>\n",
    "즉<br>\n",
    "((28,28) - (2,2)) / 2 후에 + (1,1) 은 (14,14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "pool = nn.MaxPool2d(2)\n",
    "print(pool(conv1(input_data)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "같은 방식으로 Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) 는 어떨까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (14,14) 에서 (3,3) 을 빼고 (2,2) 를 더한 후 다시 (1,1) 을 더하면 그대로 (14,14) 이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "final_output = conv2(pool(conv1(input_data)))\n",
    "print(final_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12544])\n"
     ]
    }
   ],
   "source": [
    "## CNN 의 output 을 linear layer 에 통과시켜줄 차례\n",
    "## 배치 사이즈는 그대로 두고, 나머지는 한줄로 펼치자\n",
    "out = final_output.view(final_output.shape[0], -1)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = nn.Linear(12544,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc(out).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 본격적인 CNN 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(777)\n",
    "    \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train 의 shape=(60000, 784), y_train 의 shape=(60000,)\n",
      "x_test 의 shape=(10000, 784), y_test 의 shape=(10000,)\n"
     ]
    }
   ],
   "source": [
    "from mnist import MNIST\n",
    "import numpy as np\n",
    "\n",
    "# MNIST library 를 MNIST image 파일이 있는 path 를 통해서 불러온 후 mnist 변수에 담기\n",
    "mnist = MNIST('../image_data/MNIST/MNIST/raw')\n",
    "\n",
    "# x_train, y_train, x_test, y_test 로 나누어준다\n",
    "x_train, y_train = mnist.load_training()\n",
    "x_test, y_test = mnist.load_testing()\n",
    "\n",
    "# data 는 list 형식을 되어 있으므로 shape 을 보고, 이미지 visualization 을 하기 편한 array 형태로 바꾸어준다.\n",
    "x_train=np.asarray(x_train)\n",
    "y_train=np.asarray(y_train)\n",
    "x_test=np.asarray(x_test)\n",
    "y_test=np.asarray(y_test)\n",
    "\n",
    "print(\"x_train 의 shape={}, y_train 의 shape={}\".format(x_train.shape,y_train.shape))\n",
    "print(\"x_test 의 shape={}, y_test 의 shape={}\".format(x_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert array data into Tensor Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. array 형태의 x와 y data 를 TensorDataset 형태로 train_data 에 담고\n",
    "2. 정해진 Batch size 를 이용해서 data 를 load 한 후\n",
    "3. 모델을 짜준 후에 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x data 와 y data 를 하나로 합침\n",
    "train_data = data_utils.TensorDataset(torch.FloatTensor(x_train), torch.FloatTensor(y_train))\n",
    "batch_size = 1000\n",
    "\n",
    "# batch size 별로 가져올 수 있게 data load\n",
    "trainloader = data_utils.DataLoader(train_data, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN 모델을 스스로 구현해보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  (layer1): Sequential( <br>\n",
    "    (0): Conv Layer (kernel size = 1, stride = 1, padding = 1) <br>\n",
    "    (1): Batch Normalization<br>\n",
    "    (2): ReLU <br>\n",
    "    (3): MaxPooling (kernel size = 2) <br>\n",
    "<br>\n",
    "  (layer2): Sequential( <br>\n",
    "    (0): Conv Layer (kernel size = 5, stride = 2, padding = 0) <br>\n",
    "    (1): Batch Normalization<br>\n",
    "    (2): ReLU <br>\n",
    "    (3): MaxPooling (kernel size = 2) <br>\n",
    "<br>\n",
    "  (fc): Linear(in_features=???, out_features=10) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN ,self).__init__()\n",
    "        \n",
    "        # -> CONV/FC -> BatchNorm -> ReLu(or other activation) -> Dropout -> CONV/FC ->\n",
    "        # https://stackoverflow.com/questions/39691902/ordering-of-batch-normalization-and-dropout\n",
    "    \n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size = 1, stride = 1, padding = 1),\n",
    "                                    nn.BatchNorm2d(64),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(2))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(64, 128, kernel_size = 5, stride = 2, padding = 0),\n",
    "                                    nn.BatchNorm2d(128),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(2))\n",
    "        \n",
    "        self.fc = nn.Linear(3*3*128,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        \n",
    "        out = out.view(out.shape[0], -1)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cf) Convolutional Layer 의 output 을 쉽게 구할 수 있는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv layer 를 지나고 나서 과연 어떤 size 의 tensor data 가 나올지 손쉽게 계산해 볼 수 있는 방법은 없을까? <br>\n",
    "한가지 팁으로 dummy data를 넣어보는 방법을 소개한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "방법은 간단하다.  \n",
    "dummy data를 input image 와 같은 size 로 만들고 output size 를 알아보면 된다.<br>\n",
    "물론 이때 사이즈는 28 \\* 28 이어야한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "dummy_data = torch.Tensor(1000,1,28,28).to(device) # 1000 은 bath size 를 나타냄\n",
    "print(dummy_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "중간에 conv layer 를 지나고 난 후 shape 를 확인 할 수 있도록 Conv Layer 까지만 model 을 짜본다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dummy_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(dummy_CNN ,self).__init__()\n",
    "        \n",
    "        # -> CONV/FC -> BatchNorm -> ReLu(or other activation) -> Dropout -> CONV/FC ->\n",
    "        # https://stackoverflow.com/questions/39691902/ordering-of-batch-normalization-and-dropout\n",
    "    \n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size = 1, stride = 1, padding = 1),\n",
    "                                    nn.BatchNorm2d(64),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(2))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(64, 128, kernel_size = 5, stride = 2, padding = 0),\n",
    "                                    nn.BatchNorm2d(128),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(2))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "dummy_model = dummy_CNN().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래를 통해 Conv Layer의 output 은 1000(batch size) * 128(output chennel) * 3 * 3 을 나타냄을 알 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 128, 3, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_model(dummy_data).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "즉, Linear layer 의 input 은 batch size 를 제외한 128 * 3 * 3 이 되어야한다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다시 CNN network 를 만들어보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN ,self).__init__()        \n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size = 1, stride = 1, padding = 1),\n",
    "                                    nn.BatchNorm2d(64),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(2))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(64, 128, kernel_size = 5, stride = 2, padding = 0),\n",
    "                                    nn.BatchNorm2d(128),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(2))\n",
    "        \n",
    "        self.fc = nn.Linear(3*3*128,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        \n",
    "        out = out.view(out.shape[0], -1)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 15\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model training 의 순서를 기억하시나요?\n",
    "1. x_data (image), y_data (label) 을 나누는 것\n",
    "2. gpu 메모리 위에 올려놓기\n",
    "3. gradient 0 으로 초기화\n",
    "4. model 에 data 를 넣어서 prediction 값 도출\n",
    "5. loss function 을 이용해 loss 값 구하기\n",
    "6. backpropagation\n",
    "7. weight update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1 loss = 0.6361\n",
      "Epoch = 2 loss = 0.1987\n",
      "Epoch = 3 loss = 0.1403\n",
      "Epoch = 4 loss = 0.1108\n",
      "Epoch = 5 loss = 0.0937\n",
      "Epoch = 6 loss = 0.0821\n",
      "Epoch = 7 loss = 0.0724\n",
      "Epoch = 8 loss = 0.0664\n",
      "Epoch = 9 loss = 0.0627\n",
      "Epoch = 10 loss = 0.0565\n",
      "Epoch = 11 loss = 0.0524\n",
      "Epoch = 12 loss = 0.0490\n",
      "Epoch = 13 loss = 0.0479\n",
      "Epoch = 14 loss = 0.0445\n",
      "Epoch = 15 loss = 0.0424\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "total_batch = len(trainloader) # 전체 mini batch 의 갯수\n",
    "\n",
    "for num_epoch in range(epoch):\n",
    "    avg_loss = 0\n",
    "    \n",
    "    for batch_num, (images, labels) in enumerate(trainloader):\n",
    "        # 1. x_data (image), y_data (label) 을 나누는 것\n",
    "        # 2. gpu 메모리 위에 올려놓기\n",
    "        X = images.to(device)\n",
    "        X = X.reshape(1000,1,28,28) # 1000 = batch size\n",
    "\n",
    "        #Y = torch.tensor(labels, dtype = torch.long)\n",
    "        Y = labels.to(device)\n",
    "        \n",
    "        # 3. gradient 0 으로 초기화\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 4. model 에 data 를 넣어서 prediction 값 도출\n",
    "        predict = model(X)\n",
    "        \n",
    "        # 5. loss function 을 이용해 loss 값 구하기\n",
    "        loss = loss_function(predict, Y.long())\n",
    "        \n",
    "        # 6. backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # 7. weight update\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_loss = avg_loss + (loss/total_batch)\n",
    "        \n",
    "    print(\"Epoch = {} loss = {:.4f}\".format(num_epoch+1, avg_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './pre_trained/CNN_MNIST.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./pre_trained/CNN_MNIST.pth', map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x data 와 y data 를 하나로 합침\n",
    "test_data = data_utils.TensorDataset(torch.FloatTensor(x_test), torch.FloatTensor(y_test))\n",
    "batch_size = 10000\n",
    "\n",
    "# batch size 별로 가져올 수 있게 data load\n",
    "testloader = data_utils.DataLoader(train_data, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN 을 이용한 모델의 정확도는 99.082%\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "with torch.no_grad():\n",
    "    num_total_data = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(testloader):\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        images = images.reshape(batch_size,1,28,28) # lbatch_size = 10000\n",
    "        \n",
    "        outputs = model(images).to(device)\n",
    "        outputs_softmax= torch.nn.functional.softmax(outputs, dim=1)\n",
    "        \n",
    "        # softmax 를 이용해 probability 가 가장 큰 index 를 가져옴\n",
    "        predicted = torch.argmax(outputs_softmax, dim=1)\n",
    "        \n",
    "        # len(images) 는 결국 배치 size 를 나타내는 것이므로 batch size 를 계속 더해주면 data 의 총 길이가 된다.\n",
    "        num_total_data = num_total_data + len(images)\n",
    "        \n",
    "        # 맞게 예측한 것만 세어야하는데 이때 쓸 수 있는 좋은 방법은 (True is equal to 1) 를 이용하는 것이다.\n",
    "        # itme() 을 해주면 tensor type 을 벗어던지고 단순한 float 형으로 다시 태어날 수 있다.\n",
    "        \n",
    "        answer = sum(labels==predicted).item()       \n",
    "        correct = correct + answer\n",
    "        \n",
    "print(\"CNN 을 이용한 모델의 정확도는 {:.5}%\".format((correct/num_total_data)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
