{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문자열 데이터로 RNN 학습하기\n",
    "-문자열 데이터를 벡터로 표현하기 위해 원핫인코딩(One-Hot Encoding)을 사용한다.  \n",
    "-원핫인코딩으로 표현한 데이터를 가지고 RNN을 학습한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] Data Preprocessing\n",
    "- 단어 'tomato'를 철자 단위에서 학습을 시켜보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t', 'o', 'm', 'a', 't', 'o']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = 'tomato'\n",
    "string = list(string)\n",
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'm', 'o', 't'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_string = set(string) # 중복을 허용하지 않는 데이터 타입 set\n",
    "set_string               # tomato 단어는 t, o, m, a로 구성되어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_string = ['t', 'o', 'm', 'a']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- str데이터를 원핫인코딩으로 표현한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data는 맨마지막 철자를 제외하고 입력한다\n",
    "\n",
    "encoding_X = [[[1, 0, 0, 0],   # t --> 0\n",
    "               [0, 1, 0, 0],   # o --> 1\n",
    "               [0, 0, 1, 0],   # m --> 2\n",
    "               [0, 0, 0, 1],   # a --> 3\n",
    "               [1, 0, 0, 0]]]  # t --> 0\n",
    "\n",
    "\n",
    "target = [[1, 2, 3, 0, 1]] # 처음 시작하는 철자를 제외하고 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 4])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.FloatTensor(encoding_X)\n",
    "Y = torch.LongTensor(target)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2] Model 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter \n",
    "input_size = 4  #원핫인코딩의 Dimension\n",
    "hidden_size = 4\n",
    "epoch = 20\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 선언\n",
    "model = torch.nn.RNN(input_size, hidden_size, batch_first=True)  # batch_first --> (Batch, Seq, input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function, optimizer 선언\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 0., 0., 1.],\n",
       "         [1., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3] Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9962,  0.9922, -0.9983, -0.9505],\n",
       "        [-0.8097, -0.0265,  0.9890, -0.9757],\n",
       "        [-0.9992,  0.9982, -0.9558,  0.9649],\n",
       "        [ 0.9829, -0.9983, -0.9533, -0.9934],\n",
       "        [-1.0000,  0.9991, -0.9505, -0.9894]], grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9966,  0.9925, -0.9986, -0.9541],\n",
       "         [-0.9528,  0.8018, -0.0348, -0.9695]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hidden state 값\n",
    "status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 0, 1]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9962,  0.9922, -0.9983, -0.9505],\n",
       "        [-0.8097, -0.0265,  0.9890, -0.9757],\n",
       "        [-0.9992,  0.9982, -0.9558,  0.9649],\n",
       "        [ 0.9829, -0.9983, -0.9533, -0.9934],\n",
       "        [-1.0000,  0.9991, -0.9505, -0.9894]], grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 4])\n",
      "torch.Size([1, 1, 4])\n",
      "epoch:0 loss:1.39 --> 예측한 문자:ootto, 예측값:[1 1 0 0 1]\n",
      "torch.Size([1, 5, 4])\n",
      "torch.Size([1, 1, 4])\n",
      "epoch:1 loss:1.19 --> 예측한 문자:ootto, 예측값:[1 1 0 0 1]\n",
      "torch.Size([1, 5, 4])\n",
      "torch.Size([1, 1, 4])\n",
      "epoch:2 loss:1.02 --> 예측한 문자:ooato, 예측값:[1 1 3 0 1]\n",
      "torch.Size([1, 5, 4])\n",
      "torch.Size([1, 1, 4])\n",
      "epoch:3 loss:0.88 --> 예측한 문자:omato, 예측값:[1 2 3 0 1]\n",
      "torch.Size([1, 5, 4])\n",
      "torch.Size([1, 1, 4])\n",
      "epoch:4 loss:0.76 --> 예측한 문자:omato, 예측값:[1 2 3 0 1]\n",
      "torch.Size([1, 5, 4])\n",
      "torch.Size([1, 1, 4])\n",
      "epoch:5 loss:0.67 --> 예측한 문자:omato, 예측값:[1 2 3 0 1]\n",
      "torch.Size([1, 5, 4])\n",
      "torch.Size([1, 1, 4])\n",
      "epoch:6 loss:0.58 --> 예측한 문자:omato, 예측값:[1 2 3 0 1]\n",
      "torch.Size([1, 5, 4])\n",
      "torch.Size([1, 1, 4])\n",
      "epoch:7 loss:0.51 --> 예측한 문자:omato, 예측값:[1 2 3 0 1]\n",
      "torch.Size([1, 5, 4])\n",
      "torch.Size([1, 1, 4])\n",
      "epoch:8 loss:0.46 --> 예측한 문자:omato, 예측값:[1 2 3 0 1]\n",
      "torch.Size([1, 5, 4])\n",
      "torch.Size([1, 1, 4])\n",
      "epoch:9 loss:0.42 --> 예측한 문자:omato, 예측값:[1 2 3 0 1]\n",
      "torch.Size([1, 5, 4])\n",
      "torch.Size([1, 1, 4])\n",
      "epoch:10 loss:0.40 --> 예측한 문자:omato, 예측값:[1 2 3 0 1]\n",
      "torch.Size([1, 5, 4])\n",
      "torch.Size([1, 1, 4])\n",
      "epoch:11 loss:0.38 --> 예측한 문자:omato, 예측값:[1 2 3 0 1]\n",
      "torch.Size([1, 5, 4])\n",
      "torch.Size([1, 1, 4])\n",
      "epoch:12 loss:0.37 --> 예측한 문자:omato, 예측값:[1 2 3 0 1]\n",
      "torch.Size([1, 5, 4])\n",
      "torch.Size([1, 1, 4])\n",
      "epoch:13 loss:0.36 --> 예측한 문자:omato, 예측값:[1 2 3 0 1]\n",
      "torch.Size([1, 5, 4])\n",
      "torch.Size([1, 1, 4])\n",
      "epoch:14 loss:0.36 --> 예측한 문자:omato, 예측값:[1 2 3 0 1]\n",
      "torch.Size([1, 5, 4])\n",
      "torch.Size([1, 1, 4])\n",
      "epoch:15 loss:0.36 --> 예측한 문자:omato, 예측값:[1 2 3 0 1]\n",
      "torch.Size([1, 5, 4])\n",
      "torch.Size([1, 1, 4])\n",
      "epoch:16 loss:0.35 --> 예측한 문자:omato, 예측값:[1 2 3 0 1]\n",
      "torch.Size([1, 5, 4])\n",
      "torch.Size([1, 1, 4])\n",
      "epoch:17 loss:0.35 --> 예측한 문자:omato, 예측값:[1 2 3 0 1]\n",
      "torch.Size([1, 5, 4])\n",
      "torch.Size([1, 1, 4])\n",
      "epoch:18 loss:0.35 --> 예측한 문자:omato, 예측값:[1 2 3 0 1]\n",
      "torch.Size([1, 5, 4])\n",
      "torch.Size([1, 1, 4])\n",
      "epoch:19 loss:0.35 --> 예측한 문자:omato, 예측값:[1 2 3 0 1]\n",
      "torch.Size([1, 5, 4])\n",
      "torch.Size([1, 1, 4])\n",
      "epoch:20 loss:0.35 --> 예측한 문자:omato, 예측값:[1 2 3 0 1]\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "for i in range(epoch+1):\n",
    "    optimizer.zero_grad()\n",
    "    outputs, status = model(X)\n",
    "    print(outputs.shape)\n",
    "    print(status.shape)\n",
    "    outputs = outputs.reshape(-1, input_size)\n",
    "    Y = Y.reshape(-1)\n",
    "    loss = criterion(outputs, Y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    result = outputs.detach().numpy().argmax(axis=1)\n",
    "    result = result.reshape(-1)\n",
    "    result_string = ''.join([set_string[s] for s in result])\n",
    "\n",
    "    print(f'epoch:{i} loss:{loss:.2f} --> 예측한 문자:{result_string}, 예측값:{result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4] Test\n",
    "-임의의 원핫인코딩 텐서를 입력해서 결과를 확인해본다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 4])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = torch.FloatTensor([[1, 0, 0, 0],\n",
    "                            [0, 1, 0, 0]] ) # t o m a 의 원핫인코딩값\n",
    "\n",
    "test_x = test_x.reshape(2, 1, 4)\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측한 문자: oo, 예측값:[1 1]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_output, status = model(test_x)\n",
    "    result = test_output.detach().numpy().argmax(axis=2)\n",
    "    result = result.reshape(-1)\n",
    "    result_string = ''.join([set_string[s] for s in result])\n",
    "    print(f'예측한 문자: {result_string}, 예측값:{result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
