{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN 에 대해 공부해보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Di1Y3R4CZVIM"
   },
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SOBheRS_ZVIN"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Yv5IBj_ZVIS"
   },
   "outputs": [],
   "source": [
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### GAN 의 이미지 생성을 나타내는 변화과정을 나타내기 위해 사용\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "TSHM1kgeZVIa",
    "outputId": "424d7109-a6ff-40ad-c0d5-10f106c3231f"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# for reproducibility\n",
    "random.seed(999)\n",
    "torch.manual_seed(999)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "opwDc01dZVIm"
   },
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iwSuwVNGZVIm"
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "# Noamalize옵션 빼면, 0에서 1사이\n",
    "# 넣어주면 -1에서 1사이\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "dataset = dset.MNIST(root=\"./data\", train=True, download=True ,transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, shuffle = True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, x in enumerate(dataloader):\n",
    "    plt.imshow(x[0][0].reshape(28,28), cmap=\"gray\")\n",
    "    plt.show()\n",
    "    print(x[0][0].reshape(28,28))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2JJLOUwNZVIq"
   },
   "source": [
    "### Generator & Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vCRqrfLmZVIr"
   },
   "outputs": [],
   "source": [
    "# random distribution 의 dim 은 100으로 설정\n",
    "z_size = 100\n",
    "\n",
    "# Discriminator 와 같은역할,\n",
    "# 저차원 데이터를 고차원으로 만들어 준다, 이때 최종 dim 은 이미지를 따라 28*28 로 설정\n",
    "\n",
    "# 256, 512,1024, 784\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = nn.Linear(z_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.fc3 = nn.Linear(512, 1024)\n",
    "        self.fc4 = nn.Linear(1024, 784)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2) # in practice, leaky relu >> relu\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "        \n",
    "        # generator의 아웃풋은 이미지인데 tanh -1 ~ 1범위\n",
    "        output = torch.tanh(self.fc4(x))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vCRqrfLmZVIr"
   },
   "outputs": [],
   "source": [
    "# 입력받은 이미지가 진짜인지 가짜인지 판별\n",
    "# drop_out = 0.3\n",
    "\n",
    "# 784 1024 512 256\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 1024)\n",
    "\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2) # in practice, leaky relu >> relu\n",
    "        x = F.dropout(x, 0.3)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = F.dropout(x, 0.3)\n",
    "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "        \n",
    "        # generator의 아웃풋은 sigmoid 0에서 1사이\n",
    "        output = torch.sigmoid(self.fc4(x))\n",
    "        \n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wF9bWfW9ZVIu"
   },
   "outputs": [],
   "source": [
    "netG = Generator(z_size).to(device)\n",
    "netD = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GCMG9mirZVIz"
   },
   "source": [
    "### Make Fake image without any training\n",
    "아무런 트레이닝을 하지 않은 상태에서 noise 를 만들고 Generator 에 넣어보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "just_noise = torch.randn(1, z_size).to(device)\n",
    "just_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator 를 이용해서 생성\n",
    "img_fake = netG(just_noise).reshape(28, 28)\n",
    "# 이미지 출력하기\n",
    "plt.imshow(img_fake.cpu().detach().numpy(), cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예상대로 training 을 거치지 않았으므로 noise 가 생성된다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kkDPaQK6ZVI-"
   },
   "source": [
    "### 그 밖의 Setting 들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cc52-EM4ZVI_"
   },
   "outputs": [],
   "source": [
    "num_epochs = 15\n",
    "lr = 0.0002\n",
    "\n",
    "loss_function = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Cross Entropy <br>\n",
    "\n",
    "y = 1이면, True Data. Y=0 이면 Fake Data. Discriminator 학습하는 것 BCE로 가능하다. 식을 보면 알 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B4fV0YW4ZVJJ"
   },
   "outputs": [],
   "source": [
    "# Noise 하나를 fix 시켜서 변수에 담아준다. 학습을 하면서 생성되는 image 의 변화를 관찰 할 수 있다\n",
    "# fixed_noise 라는 변수는 epoch 단위로 학습이 끝날때마다 netG 안으로 들어가서 어떠한 이미지를 generation 할 것이다\n",
    "# 그것을 순서대로 담아서 앞에서부터 출력해주면 똑같은 noise 가 epoch 가 진행될 수록 어떻게 image 형태가 잘 나오는지의\n",
    "# 변화를 볼 수 있다\n",
    "\n",
    "\n",
    "# epoch마다 이미지 체크용\n",
    "fixed_noise = torch.randn(64, z_size).to(device)\n",
    "fixed_noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RZ5y-IUqZVJO"
   },
   "outputs": [],
   "source": [
    "# Discriminator 가 real 혹은 false 로 판단할 수 있게끔 scalar 값으로 labeling을 해준다\n",
    "# 여기에 설정해둔 값으로 loss 를 구하게 된다\n",
    "real_label = 1\n",
    "fake_label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Prb6j2GwZVJS"
   },
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999)) # DCgan paper -> 0.9 에서 0.5 로\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "betas Adam에 들어가던 파라미터인데, 이렇게 쓰니깐 잘되더라 하고 논문에 써있어서 추가함. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IEK0FjwTZVJZ"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data load\n",
    "2. Discriminator를 True Data로 훈련\n",
    "3. Discriminator를 Fake Data로 훈련\n",
    "4. Generator 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 843
    },
    "colab_type": "code",
    "id": "ClmLiV2VZVJZ",
    "outputId": "a14b2265-f8e9-4a0f-e7bf-3609065306a2"
   },
   "outputs": [],
   "source": [
    "# 생성되는 이미지를 저장할 빈 리스트\n",
    "img_list = []\n",
    "\n",
    "# loss 값을 저장할 빈 리스트\n",
    "G_losses = []\n",
    "D_losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN 의 original 논문과 함께 Discriminator 를 먼저 학습한 후 Generator 를 학습한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.full((100,), 1, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 28, 28])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 843
    },
    "colab_type": "code",
    "id": "ClmLiV2VZVJZ",
    "outputId": "a14b2265-f8e9-4a0f-e7bf-3609065306a2"
   },
   "outputs": [],
   "source": [
    "# minibatch 가 몇번 학습했는지를 나타내는 총 itertaion 을 계산\n",
    "# 즉, batch size 는 100이고 데이터의 총 갯수는 60000개 이므로 iteration 은 600 이다.\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(dataloader): # 기존에는 i 를 batch_idx 로 해주고 data 를 (image, label) 로 하였음\n",
    "        \n",
    "        ###################################################################################################################\n",
    "        # =================================================================== #\n",
    "        # (1) Update Discriminator\n",
    "        # [LogD(x) + Log(1-D(G(z)))]\n",
    "        # =================================================================== #\n",
    "        \n",
    "        #####################################################\n",
    "        # 1. Real Image 로 Discriminator 훈련 (LogD(x) 부분)\n",
    "        # LogD(x) 를 1로 판단 할 수 있어야 한다\n",
    "        #####################################################\n",
    "        netD.zero_grad()        \n",
    "        # data[0] = image data 를 나타냄\n",
    "        # data[1] = image label 을 나타냄\n",
    "        # real_cpu = real 그림 이미지를 나타내는 변수\n",
    "        real_cpu = data[0]\n",
    "        b_size = real_cpu.size(0)\n",
    "        real_cpu = real_cpu.reshape(b_size, -1).to(device) # 28*28 => 784\n",
    "        \n",
    "        # label 의 경우 torch 형태로 (1,1,1,1,1,1,1, ... 이 batch size 만큼 들어가있다 (discriminator 와 결과와 비교하기 위해))\n",
    "        label = torch.full((b_size,), 1, dtype=torch.float32).to(device)\n",
    "        # print(label) 해보면 아래와 같이 나옴\n",
    "        \"\"\"\n",
    "        tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
    "                1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
    "                1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
    "                1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
    "                1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
    "                1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
    "        \"\"\"\n",
    "\n",
    "        output =  netD(real_cpu).view(-1).to(device) # torch.Size([100, 1]) => output.shape 이므로 view(-1 을 해서 Size[100] 으로 변환)\n",
    "        \n",
    "        \"\"\"\n",
    "        Loss function 은 BCE 이다. 또한 y 값은 1로 고정이 되어있다 (true data 이므로)\n",
    "        BCE 의 공식에 y = 1 을 넣으면 뒤의 항은 0이 되어서 사라지게 되고 앞의 항 LogD(x) 만 남게된다\n",
    "        \"\"\"\n",
    "        errD_real = loss_function(output, label) # => LogD(x)\n",
    "        \n",
    "        # real image 에 대한 back propagation\n",
    "        errD_real.backward()\n",
    "        \n",
    "        # 여기서 output의 평균값이면, 1이 나와야 되는데, 얼마나 잘 판단하고 있는지를 나타내겠지. \n",
    "        D_x = output.mean().item()  # mini batch 마다 D(x) 의 평균값을 구하기 위해 D_x 에 따로 저장\n",
    "\n",
    "        ######################################\n",
    "        # 2. Fake Image 로 Discriminator 훈련\n",
    "        ######################################\n",
    "        \n",
    "        # Generator 에 들어갈 noise 생성\n",
    "        noise = torch.randn(b_size, z_size).to(device) # 배치 size, noise size\n",
    "        \n",
    "        # Generate 에서 fake image 생성 (Discriminator 가 분간해야 하는 image) -> 전부 0이라고 구분해야 정상이다\n",
    "        fake = netG(noise)\n",
    "        \n",
    "        # 위에서 미리 만들어둔 label 을 이번에는 0,0,0,0,0,0,...으로 채워준다\n",
    "        label.fill_(fake_label).to(device)\n",
    "        \n",
    "        # Noise 를 Discriminator에 넣어보자\n",
    "        # .detach() 가 필수로 들어가야 한다 (이미 netD 를 한번 사용 했으므로)\n",
    "        '''\n",
    "        # (https://discuss.pytorch.org/t/runtimeerror-trying-to-backward-through-the-graph-a-second-time-\n",
    "        # but-the-buffers-have-already-been-freed-specify-retain-graph-true-when-calling-backward-the-first-time-\n",
    "        # while-using-custom-loss-function/12360/2)\n",
    "        '''\n",
    "        # Gradient만 내비두고, buffer초기화 해야함. 그 명령어가 detach\n",
    "        output = netD(fake.detach()).view(-1).to(device) # Fake data 입력\n",
    "        errD_fake = loss_function(output, label) # 이번에는 Y 가 0 이므로 log(1-D(G(z))) 가 남게 된다\n",
    "\n",
    "        errD_fake.backward() # back propagation\n",
    "        \n",
    "        # 여기서 output의 평균값이면, 0이 나와야 되는데, 얼마나 잘 판단하고 있는지를 나타내겠지. \n",
    "        D_G_z1 = output.mean().item()\n",
    "\n",
    "        errD = errD_real + errD_fake # Discriminator 의 Error 를 구해보자\n",
    "        \n",
    "        # Update Discriminator\n",
    "        optimizerD.step()\n",
    "        ###################################################################################################################\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ###################################################################################################################\n",
    "        # =================================================================== #\n",
    "        # (2) Update Generator\n",
    "        #  [LogD(G(z))] \n",
    "        # =================================================================== #\n",
    "        # Generator 는 만들어낸 image 가 discriminator 로 하여금 1 (real) 로 판단 할 수 있게 훈련시켜야 한다\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)\n",
    "        \n",
    "        # 위에서 만든 fake랑 똑같은 데이터\n",
    "        output = netD(fake).view(-1).to(device)\n",
    "        \n",
    "        errG = loss_function(output, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        \n",
    "        optimizerG.step()\n",
    "        \n",
    "        # Training 경과를 관찰하기 위해 print\n",
    "        if i % 200 == 0:\n",
    "            # Print 문을 사용해서 어떤것을 출력하는 걸까?\n",
    "            # [현재 epoch/전체 epoch][현재 iteration/전체 itertation]\n",
    "            # Discriminator 의 loss, D(Real_image), D 를 훈련하기 전의 D(fake), D 를 훈련한 후의 D(fake)\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, len(dataloader),\n",
    "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "        \n",
    "        # Plotting 을 하기 위해서 list 에 loss 값을 넣어준다\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "        \n",
    "        # 또한 iteration 을 돌리면서 중간중간 생성되는 image 값을 저장하여 결과를 지켜보도록하자\n",
    "        # ((epoch == num_epochs-1) and (batch_size == len(trainloader)-1))\n",
    "        #   → 가장 마지막 epoch 에서 가장 마지막 minibatch 를 학습할 때의 시점 (맨 마지막 학습 결과)\n",
    "        \n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu() # netG 를 다시 사용해야 하므로 detach 를 붙여줌\n",
    "                fake = fake.reshape(-1,1,28,28)\n",
    "            img_list.append(vutils.make_grid(fake, normalize=True)) # If normalize=True, shift the image to the range (0, 1)\n",
    "            \n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D(G(z)): 0.5141 / 0.5142\n",
    "\n",
    "훈련하기 전과 후를 나타낸다. Discriminator에 Fake Image를 넣었을 때, 얼마나 잘 구분하는지. \n",
    "\n",
    "결론만 말하면, True Data, Fake Image에 대해 Discriminator가 헷갈려야 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사실 훈련이 잘 안되는게, Discriminator가 Generator가 잘 훈련되기 전에 너무 앞서나가면, Generator가 뭔 짓을 해도 소용이 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image list 를 pt 로 저장\n",
    "torch.save(img_list, './pickle/GAN_01_FeedForward_GAN_epoch'+str(num_epochs) +'.pt')\n",
    "\n",
    "# G 를 앞으로 사용할 수 있게 저장\n",
    "torch.save(netG.state_dict(), './pre_trained/GAN_01_FeedForward_GAN_epoch'+str(num_epochs) +'.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "id": "P3YTKBvzZVJi",
    "outputId": "8ea7148b-25d4-4354-9906-056712b7b884",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real image 와 fake image 를 한눈에 살펴보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = torch.load('./pickle/GAN_01_FeedForward_GAN_epoch'+str(num_epochs) +'.pt', map_location  = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x39OrMUOZVJ3"
   },
   "outputs": [],
   "source": [
    "# real image 를 담을 list 를 준비 & image 담기\n",
    "sample_image = []\n",
    "\n",
    "for i, data in enumerate(dataloader):\n",
    "    sample_image.append(data[0][range(64)])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "colab_type": "code",
    "id": "idXcEghYZVJ5",
    "outputId": "65e3ed78-de10-4b79-fac3-11af867e0fcd",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the real images\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(sample_image[0], normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "# Plot the fake images from the last epoch\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "\n",
    "plt.imshow(np.transpose(img_list[-1].cpu(),(1,2,0)))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WyQgVgxgZVKC"
   },
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wb_clnP9ZVKC"
   },
   "outputs": [],
   "source": [
    "netG = Generator(100).to(device) # random distribution 의 dim 은 100으로 설정했으므로 100 을 넣어야한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1DQSEa5RZVKG",
    "outputId": "8203c725-30f3-4449-8b28-37ee5c224e38"
   },
   "outputs": [],
   "source": [
    "netG.load_state_dict(torch.load('./pickle/GAN_01_FeedForward_GAN_epoch' + str(num_epochs) +'.pth',  map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fsx3KDYvZVKJ"
   },
   "source": [
    "### Generate amy images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V4lbvYDzZVKJ"
   },
   "outputs": [],
   "source": [
    "z_noise = torch.randn(5, z_size).to(device) # 5개만 생성\n",
    "image = netG(z_noise).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "FQs7UkHsZVKM",
    "outputId": "e54cbdbb-9af0-4d6b-e5b8-956dc0b383f1",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for generated in (image):\n",
    "    plt.imshow(generated.detach().numpy().reshape(28,28), cmap=\"gray\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
