{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from lib.envs.gridworld import GridworldEnv # 상위 폴더내의 lib 폴더 -> env 폴더 -> gridworld.py 파일에서 GridwordlEnv 를 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GridworldEnv() # 강화학습을 위한 환경을 env 변수에 넣음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(env, theta=0.0001, discount_factor=1.0):\n",
    "    \n",
    "    # Policy iteration 과 같다 (q 값을 구해주는 부분)\n",
    "    def one_step_lookahead(state, State_Value):\n",
    "        action_value = np.zeros(env.nA)\n",
    "        for action in range(env.nA):\n",
    "            for transition_prob, next_state, reward, done in env.P[state][action]:\n",
    "                # 교재 251 page의 max 안쪽 부분\n",
    "                action_value[action] += reward + (discount_factor * transition_prob * State_Value[next_state])\n",
    "        return action_value\n",
    "    \n",
    "    \n",
    "# ============================================================================================\n",
    "    # Value Iteration 시작!!!\n",
    "    # 각 state 의 value 값을 0으로 초기화\n",
    "    state_value = np.zeros(env.nS)\n",
    "    \n",
    "    while True:\n",
    "        # while loop 가 언제 멈출지 알기 위해 delta 를 설정\n",
    "        # delta 의 경우 iteration 전과 후의 차이의 절대값으로 설정된다 \n",
    "        delta = 0\n",
    "        \n",
    "        # Optimal Value 를 찾기 위해 loop 를 돌며 value 값 update 실행\n",
    "        for state in range(env.nS):\n",
    "            print(\"======================================================\")\n",
    "            print(\"State =>\", state)\n",
    "            # lookahead 방법을 통해 update\n",
    "            # state 마다 돌면서 value 값을 update 해준다 # 교재 251 page의 max 안쪽 부분\n",
    "            \n",
    "            # 현재 V로 현재 state의 Q값 업데이트. \n",
    "            action_value = one_step_lookahead(state, state_value)\n",
    "            \n",
    "            # Q값 가지고, 현재 V를 다시 업데이트. \n",
    "            # 교재 251 page max 부분 수행\n",
    "            max_value = np.max(action_value)\n",
    "            print(\"action_value\", action_value)\n",
    "            print(\"max_value\", max_value)\n",
    "            \n",
    "            # 기존 value 값과 새로 update 한 value 값이 얼마나 변했는지 구해준다 (이후에 theshold 값과 비교 할 것임)\n",
    "            delta = max(delta, np.abs(max_value - state_value[state]))\n",
    "            \n",
    "            # Value fucntion 을 update\n",
    "            state_value[state] = max_value      \n",
    "            print(\"state\", state , \"의 value는 \", state_value[state], \"\\n\") \n",
    "            \n",
    "                   \n",
    "        # while loop 를 멈출지 더 실행시킬지 확인해본다 \n",
    "        if delta < theta:\n",
    "            print(\"delta 값이\",delta,\"이므로 while 문 멈춤\\n\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"delta 값이\",delta,\"이므로 while 문 계속해서 수행\\n\")\n",
    "                \n",
    "    \n",
    "# ============================================================================================\n",
    "    # State 별로 최적의 value 값을 구했다면 optimal value 값을 따라 policy 를 찾아준다\n",
    "    # policy.shape = (16, 4)\n",
    "    # 즉, state 별로 초기값을 0으로 설정한 policy 를 할당 해주는 것\n",
    "    # 잘 이해가 안된다면 4번 cell의 코드를 실행시켜보자\n",
    "    policy = np.zeros([env.nS, env.nA]) \n",
    "    \n",
    "    print(\"Optimal Value 를 따라 policy 를 찾아주도록 한다.\\n\")\n",
    "    for state in range(env.nS):\n",
    "        \n",
    "        print(\"Optimal value =>\\n\", state_value.reshape([4,4]))\n",
    "        \n",
    "        # Optimal Value 값을 찾았으니 optimal policy를 찾아주도록 하자\n",
    "        action_value = one_step_lookahead(state, state_value)\n",
    "        print(\"state\",state,\"에서 모든 action 에 관한 Action_value =>\", action_value)\n",
    "        best_action = np.argmax(action_value)\n",
    "        print(\"Best action 은?\", best_action, \"\\n\")\n",
    "        # 항상 best action 을 선택할 수 있도록 해당 state 의 해당 action 확률을 1로 해준다.\n",
    "        policy[state, best_action] = 1.0\n",
    "        # print(policy)\n",
    "    \n",
    "    return policy, state_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================\n",
      "State => 0\n",
      "action_value [0. 0. 0. 0.]\n",
      "max_value 0.0\n",
      "state 0 의 value는  0.0 \n",
      "\n",
      "======================================================\n",
      "State => 1\n",
      "action_value [-1. -1. -1. -1.]\n",
      "max_value -1.0\n",
      "state 1 의 value는  -1.0 \n",
      "\n",
      "======================================================\n",
      "State => 2\n",
      "action_value [-1. -1. -1. -2.]\n",
      "max_value -1.0\n",
      "state 2 의 value는  -1.0 \n",
      "\n",
      "======================================================\n",
      "State => 3\n",
      "action_value [-1. -1. -1. -2.]\n",
      "max_value -1.0\n",
      "state 3 의 value는  -1.0 \n",
      "\n",
      "======================================================\n",
      "State => 4\n",
      "action_value [-1. -1. -1. -1.]\n",
      "max_value -1.0\n",
      "state 4 의 value는  -1.0 \n",
      "\n",
      "======================================================\n",
      "State => 5\n",
      "action_value [-2. -1. -1. -2.]\n",
      "max_value -1.0\n",
      "state 5 의 value는  -1.0 \n",
      "\n",
      "======================================================\n",
      "State => 6\n",
      "action_value [-2. -1. -1. -2.]\n",
      "max_value -1.0\n",
      "state 6 의 value는  -1.0 \n",
      "\n",
      "======================================================\n",
      "State => 7\n",
      "action_value [-2. -1. -1. -2.]\n",
      "max_value -1.0\n",
      "state 7 의 value는  -1.0 \n",
      "\n",
      "======================================================\n",
      "State => 8\n",
      "action_value [-2. -1. -1. -1.]\n",
      "max_value -1.0\n",
      "state 8 의 value는  -1.0 \n",
      "\n",
      "======================================================\n",
      "State => 9\n",
      "action_value [-2. -1. -1. -2.]\n",
      "max_value -1.0\n",
      "state 9 의 value는  -1.0 \n",
      "\n",
      "======================================================\n",
      "State => 10\n",
      "action_value [-2. -1. -1. -2.]\n",
      "max_value -1.0\n",
      "state 10 의 value는  -1.0 \n",
      "\n",
      "======================================================\n",
      "State => 11\n",
      "action_value [-2. -1. -1. -2.]\n",
      "max_value -1.0\n",
      "state 11 의 value는  -1.0 \n",
      "\n",
      "======================================================\n",
      "State => 12\n",
      "action_value [-2. -1. -1. -1.]\n",
      "max_value -1.0\n",
      "state 12 의 value는  -1.0 \n",
      "\n",
      "======================================================\n",
      "State => 13\n",
      "action_value [-2. -1. -1. -2.]\n",
      "max_value -1.0\n",
      "state 13 의 value는  -1.0 \n",
      "\n",
      "======================================================\n",
      "State => 14\n",
      "action_value [-2. -1. -1. -2.]\n",
      "max_value -1.0\n",
      "state 14 의 value는  -1.0 \n",
      "\n",
      "======================================================\n",
      "State => 15\n",
      "action_value [0. 0. 0. 0.]\n",
      "max_value 0.0\n",
      "state 15 의 value는  0.0 \n",
      "\n",
      "delta 값이 1.0 이므로 while 문 계속해서 수행\n",
      "\n",
      "======================================================\n",
      "State => 0\n",
      "action_value [0. 0. 0. 0.]\n",
      "max_value 0.0\n",
      "state 0 의 value는  0.0 \n",
      "\n",
      "======================================================\n",
      "State => 1\n",
      "action_value [-2. -2. -2. -1.]\n",
      "max_value -1.0\n",
      "state 1 의 value는  -1.0 \n",
      "\n",
      "======================================================\n",
      "State => 2\n",
      "action_value [-2. -2. -2. -2.]\n",
      "max_value -2.0\n",
      "state 2 의 value는  -2.0 \n",
      "\n",
      "======================================================\n",
      "State => 3\n",
      "action_value [-2. -2. -2. -3.]\n",
      "max_value -2.0\n",
      "state 3 의 value는  -2.0 \n",
      "\n",
      "======================================================\n",
      "State => 4\n",
      "action_value [-1. -2. -2. -2.]\n",
      "max_value -1.0\n",
      "state 4 의 value는  -1.0 \n",
      "\n",
      "======================================================\n",
      "State => 5\n",
      "action_value [-2. -2. -2. -2.]\n",
      "max_value -2.0\n",
      "state 5 의 value는  -2.0 \n",
      "\n",
      "======================================================\n",
      "State => 6\n",
      "action_value [-3. -2. -2. -3.]\n",
      "max_value -2.0\n",
      "state 6 의 value는  -2.0 \n",
      "\n",
      "======================================================\n",
      "State => 7\n",
      "action_value [-3. -2. -2. -3.]\n",
      "max_value -2.0\n",
      "state 7 의 value는  -2.0 \n",
      "\n",
      "======================================================\n",
      "State => 8\n",
      "action_value [-2. -2. -2. -2.]\n",
      "max_value -2.0\n",
      "state 8 의 value는  -2.0 \n",
      "\n",
      "======================================================\n",
      "State => 9\n",
      "action_value [-3. -2. -2. -3.]\n",
      "max_value -2.0\n",
      "state 9 의 value는  -2.0 \n",
      "\n",
      "======================================================\n",
      "State => 10\n",
      "action_value [-3. -2. -2. -3.]\n",
      "max_value -2.0\n",
      "state 10 의 value는  -2.0 \n",
      "\n",
      "======================================================\n",
      "State => 11\n",
      "action_value [-3. -2. -1. -3.]\n",
      "max_value -1.0\n",
      "state 11 의 value는  -1.0 \n",
      "\n",
      "======================================================\n",
      "State => 12\n",
      "action_value [-3. -2. -2. -2.]\n",
      "max_value -2.0\n",
      "state 12 의 value는  -2.0 \n",
      "\n",
      "======================================================\n",
      "State => 13\n",
      "action_value [-3. -2. -2. -3.]\n",
      "max_value -2.0\n",
      "state 13 의 value는  -2.0 \n",
      "\n",
      "======================================================\n",
      "State => 14\n",
      "action_value [-3. -1. -2. -3.]\n",
      "max_value -1.0\n",
      "state 14 의 value는  -1.0 \n",
      "\n",
      "======================================================\n",
      "State => 15\n",
      "action_value [0. 0. 0. 0.]\n",
      "max_value 0.0\n",
      "state 15 의 value는  0.0 \n",
      "\n",
      "delta 값이 1.0 이므로 while 문 계속해서 수행\n",
      "\n",
      "======================================================\n",
      "State => 0\n",
      "action_value [0. 0. 0. 0.]\n",
      "max_value 0.0\n",
      "state 0 의 value는  0.0 \n",
      "\n",
      "======================================================\n",
      "State => 1\n",
      "action_value [-2. -3. -3. -1.]\n",
      "max_value -1.0\n",
      "state 1 의 value는  -1.0 \n",
      "\n",
      "======================================================\n",
      "State => 2\n",
      "action_value [-3. -3. -3. -2.]\n",
      "max_value -2.0\n",
      "state 2 의 value는  -2.0 \n",
      "\n",
      "======================================================\n",
      "State => 3\n",
      "action_value [-3. -3. -3. -3.]\n",
      "max_value -3.0\n",
      "state 3 의 value는  -3.0 \n",
      "\n",
      "======================================================\n",
      "State => 4\n",
      "action_value [-1. -3. -3. -2.]\n",
      "max_value -1.0\n",
      "state 4 의 value는  -1.0 \n",
      "\n",
      "======================================================\n",
      "State => 5\n",
      "action_value [-2. -3. -3. -2.]\n",
      "max_value -2.0\n",
      "state 5 의 value는  -2.0 \n",
      "\n",
      "======================================================\n",
      "State => 6\n",
      "action_value [-3. -3. -3. -3.]\n",
      "max_value -3.0\n",
      "state 6 의 value는  -3.0 \n",
      "\n",
      "======================================================\n",
      "State => 7\n",
      "action_value [-4. -3. -2. -4.]\n",
      "max_value -2.0\n",
      "state 7 의 value는  -2.0 \n",
      "\n",
      "======================================================\n",
      "State => 8\n",
      "action_value [-2. -3. -3. -3.]\n",
      "max_value -2.0\n",
      "state 8 의 value는  -2.0 \n",
      "\n",
      "======================================================\n",
      "State => 9\n",
      "action_value [-3. -3. -3. -3.]\n",
      "max_value -3.0\n",
      "state 9 의 value는  -3.0 \n",
      "\n",
      "======================================================\n",
      "State => 10\n",
      "action_value [-4. -2. -2. -4.]\n",
      "max_value -2.0\n",
      "state 10 의 value는  -2.0 \n",
      "\n",
      "======================================================\n",
      "State => 11\n",
      "action_value [-3. -2. -1. -3.]\n",
      "max_value -1.0\n",
      "state 11 의 value는  -1.0 \n",
      "\n",
      "======================================================\n",
      "State => 12\n",
      "action_value [-3. -3. -3. -3.]\n",
      "max_value -3.0\n",
      "state 12 의 value는  -3.0 \n",
      "\n",
      "======================================================\n",
      "State => 13\n",
      "action_value [-4. -2. -3. -4.]\n",
      "max_value -2.0\n",
      "state 13 의 value는  -2.0 \n",
      "\n",
      "======================================================\n",
      "State => 14\n",
      "action_value [-3. -1. -2. -3.]\n",
      "max_value -1.0\n",
      "state 14 의 value는  -1.0 \n",
      "\n",
      "======================================================\n",
      "State => 15\n",
      "action_value [0. 0. 0. 0.]\n",
      "max_value 0.0\n",
      "state 15 의 value는  0.0 \n",
      "\n",
      "delta 값이 1.0 이므로 while 문 계속해서 수행\n",
      "\n",
      "======================================================\n",
      "State => 0\n",
      "action_value [0. 0. 0. 0.]\n",
      "max_value 0.0\n",
      "state 0 의 value는  0.0 \n",
      "\n",
      "======================================================\n",
      "State => 1\n",
      "action_value [-2. -3. -3. -1.]\n",
      "max_value -1.0\n",
      "state 1 의 value는  -1.0 \n",
      "\n",
      "======================================================\n",
      "State => 2\n",
      "action_value [-3. -4. -4. -2.]\n",
      "max_value -2.0\n",
      "state 2 의 value는  -2.0 \n",
      "\n",
      "======================================================\n",
      "State => 3\n",
      "action_value [-4. -4. -3. -3.]\n",
      "max_value -3.0\n",
      "state 3 의 value는  -3.0 \n",
      "\n",
      "======================================================\n",
      "State => 4\n",
      "action_value [-1. -3. -3. -2.]\n",
      "max_value -1.0\n",
      "state 4 의 value는  -1.0 \n",
      "\n",
      "======================================================\n",
      "State => 5\n",
      "action_value [-2. -4. -4. -2.]\n",
      "max_value -2.0\n",
      "state 5 의 value는  -2.0 \n",
      "\n",
      "======================================================\n",
      "State => 6\n",
      "action_value [-3. -3. -3. -3.]\n",
      "max_value -3.0\n",
      "state 6 의 value는  -3.0 \n",
      "\n",
      "======================================================\n",
      "State => 7\n",
      "action_value [-4. -3. -2. -4.]\n",
      "max_value -2.0\n",
      "state 7 의 value는  -2.0 \n",
      "\n",
      "======================================================\n",
      "State => 8\n",
      "action_value [-2. -4. -4. -3.]\n",
      "max_value -2.0\n",
      "state 8 의 value는  -2.0 \n",
      "\n",
      "======================================================\n",
      "State => 9\n",
      "action_value [-3. -3. -3. -3.]\n",
      "max_value -3.0\n",
      "state 9 의 value는  -3.0 \n",
      "\n",
      "======================================================\n",
      "State => 10\n",
      "action_value [-4. -2. -2. -4.]\n",
      "max_value -2.0\n",
      "state 10 의 value는  -2.0 \n",
      "\n",
      "======================================================\n",
      "State => 11\n",
      "action_value [-3. -2. -1. -3.]\n",
      "max_value -1.0\n",
      "state 11 의 value는  -1.0 \n",
      "\n",
      "======================================================\n",
      "State => 12\n",
      "action_value [-3. -3. -4. -4.]\n",
      "max_value -3.0\n",
      "state 12 의 value는  -3.0 \n",
      "\n",
      "======================================================\n",
      "State => 13\n",
      "action_value [-4. -2. -3. -4.]\n",
      "max_value -2.0\n",
      "state 13 의 value는  -2.0 \n",
      "\n",
      "======================================================\n",
      "State => 14\n",
      "action_value [-3. -1. -2. -3.]\n",
      "max_value -1.0\n",
      "state 14 의 value는  -1.0 \n",
      "\n",
      "======================================================\n",
      "State => 15\n",
      "action_value [0. 0. 0. 0.]\n",
      "max_value 0.0\n",
      "state 15 의 value는  0.0 \n",
      "\n",
      "delta 값이 0 이므로 while 문 멈춤\n",
      "\n",
      "Optimal Value 를 따라 policy 를 찾아주도록 한다.\n",
      "\n",
      "Optimal value =>\n",
      " [[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -2.]\n",
      " [-2. -3. -2. -1.]\n",
      " [-3. -2. -1.  0.]]\n",
      "state 0 에서 모든 action 에 관한 Action_value => [0. 0. 0. 0.]\n",
      "Best action 은? 0 \n",
      "\n",
      "Optimal value =>\n",
      " [[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -2.]\n",
      " [-2. -3. -2. -1.]\n",
      " [-3. -2. -1.  0.]]\n",
      "state 1 에서 모든 action 에 관한 Action_value => [-2. -3. -3. -1.]\n",
      "Best action 은? 3 \n",
      "\n",
      "Optimal value =>\n",
      " [[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -2.]\n",
      " [-2. -3. -2. -1.]\n",
      " [-3. -2. -1.  0.]]\n",
      "state 2 에서 모든 action 에 관한 Action_value => [-3. -4. -4. -2.]\n",
      "Best action 은? 3 \n",
      "\n",
      "Optimal value =>\n",
      " [[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -2.]\n",
      " [-2. -3. -2. -1.]\n",
      " [-3. -2. -1.  0.]]\n",
      "state 3 에서 모든 action 에 관한 Action_value => [-4. -4. -3. -3.]\n",
      "Best action 은? 2 \n",
      "\n",
      "Optimal value =>\n",
      " [[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -2.]\n",
      " [-2. -3. -2. -1.]\n",
      " [-3. -2. -1.  0.]]\n",
      "state 4 에서 모든 action 에 관한 Action_value => [-1. -3. -3. -2.]\n",
      "Best action 은? 0 \n",
      "\n",
      "Optimal value =>\n",
      " [[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -2.]\n",
      " [-2. -3. -2. -1.]\n",
      " [-3. -2. -1.  0.]]\n",
      "state 5 에서 모든 action 에 관한 Action_value => [-2. -4. -4. -2.]\n",
      "Best action 은? 0 \n",
      "\n",
      "Optimal value =>\n",
      " [[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -2.]\n",
      " [-2. -3. -2. -1.]\n",
      " [-3. -2. -1.  0.]]\n",
      "state 6 에서 모든 action 에 관한 Action_value => [-3. -3. -3. -3.]\n",
      "Best action 은? 0 \n",
      "\n",
      "Optimal value =>\n",
      " [[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -2.]\n",
      " [-2. -3. -2. -1.]\n",
      " [-3. -2. -1.  0.]]\n",
      "state 7 에서 모든 action 에 관한 Action_value => [-4. -3. -2. -4.]\n",
      "Best action 은? 2 \n",
      "\n",
      "Optimal value =>\n",
      " [[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -2.]\n",
      " [-2. -3. -2. -1.]\n",
      " [-3. -2. -1.  0.]]\n",
      "state 8 에서 모든 action 에 관한 Action_value => [-2. -4. -4. -3.]\n",
      "Best action 은? 0 \n",
      "\n",
      "Optimal value =>\n",
      " [[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -2.]\n",
      " [-2. -3. -2. -1.]\n",
      " [-3. -2. -1.  0.]]\n",
      "state 9 에서 모든 action 에 관한 Action_value => [-3. -3. -3. -3.]\n",
      "Best action 은? 0 \n",
      "\n",
      "Optimal value =>\n",
      " [[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -2.]\n",
      " [-2. -3. -2. -1.]\n",
      " [-3. -2. -1.  0.]]\n",
      "state 10 에서 모든 action 에 관한 Action_value => [-4. -2. -2. -4.]\n",
      "Best action 은? 1 \n",
      "\n",
      "Optimal value =>\n",
      " [[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -2.]\n",
      " [-2. -3. -2. -1.]\n",
      " [-3. -2. -1.  0.]]\n",
      "state 11 에서 모든 action 에 관한 Action_value => [-3. -2. -1. -3.]\n",
      "Best action 은? 2 \n",
      "\n",
      "Optimal value =>\n",
      " [[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -2.]\n",
      " [-2. -3. -2. -1.]\n",
      " [-3. -2. -1.  0.]]\n",
      "state 12 에서 모든 action 에 관한 Action_value => [-3. -3. -4. -4.]\n",
      "Best action 은? 0 \n",
      "\n",
      "Optimal value =>\n",
      " [[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -2.]\n",
      " [-2. -3. -2. -1.]\n",
      " [-3. -2. -1.  0.]]\n",
      "state 13 에서 모든 action 에 관한 Action_value => [-4. -2. -3. -4.]\n",
      "Best action 은? 1 \n",
      "\n",
      "Optimal value =>\n",
      " [[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -2.]\n",
      " [-2. -3. -2. -1.]\n",
      " [-3. -2. -1.  0.]]\n",
      "state 14 에서 모든 action 에 관한 Action_value => [-3. -1. -2. -3.]\n",
      "Best action 은? 1 \n",
      "\n",
      "Optimal value =>\n",
      " [[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -2.]\n",
      " [-2. -3. -2. -1.]\n",
      " [-3. -2. -1.  0.]]\n",
      "state 15 에서 모든 action 에 관한 Action_value => [0. 0. 0. 0.]\n",
      "Best action 은? 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "policy, v = value_iteration(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Probability Distribution:\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n",
      "\n",
      "Reshaped Grid Policy (0=up, 1=right, 2=down, 3=left):\n",
      "[[0 3 3 2]\n",
      " [0 0 0 2]\n",
      " [0 0 1 2]\n",
      " [0 1 1 0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Policy Probability Distribution:\")\n",
    "print(policy)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Reshaped Grid Policy (0=up, 1=right, 2=down, 3=left):\")\n",
    "print(np.reshape(np.argmax(policy, axis=1), env.shape)) # axis = 1 이면 행끼리 연산을 수행\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Function:\n",
      "[ 0. -1. -2. -3. -1. -2. -3. -2. -2. -3. -2. -1. -3. -2. -1.  0.]\n",
      "\n",
      "Reshaped Grid Value Function:\n",
      "[[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -2.]\n",
      " [-2. -3. -2. -1.]\n",
      " [-3. -2. -1.  0.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Value Function:\")\n",
    "print(v)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Reshaped Grid Value Function:\")\n",
    "print(v.reshape(env.shape))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
